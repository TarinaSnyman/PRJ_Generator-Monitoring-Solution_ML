{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2002475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to install in terminal\n",
    "# pip install torch torchtuples lifelines\n",
    "# pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95260299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torchtuples as tt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d19a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(\"../../data/raw/air_12318.csv\", on_bad_lines='skip')\n",
    "df = df.sort_values(\"time\").reset_index(drop=True) #sort by date\n",
    "\n",
    "# generator state --double chack that is correct\n",
    "df['is_running'] = (\n",
    "    (df[['ia_A','ib_A','ic_A','pa_W','pb_W','pc_W']].sum(axis=1) > 0) | \n",
    "    (df['pressure_Bar'] > 0)  \n",
    ").astype(int)\n",
    "\n",
    "\n",
    "numeric_cols = [\n",
    "    'va_V','vb_V','vc_V','va-vb_V','vb-vc_V','vc-va_V',\n",
    "    'mVa_V','mVb_V','mVc_v','mVa-mBb_V','mVb-mVc_V','mVc-mVa_V',\n",
    "    'ia_A','ib_A','ic_A','pa_W','pb_W','pc_W','ptot_W',\n",
    "    'qa_Var','qb_Var','qc_Var','qtot_Var','sa_VA','sb_VA','sc_VA','stot_VA',\n",
    "    'pfa_None','pfb_None','pfc_None','pftot_None','freq_Hz*10',\n",
    "    'temp_Degrees Celsius','pressure_Bar','fuel_%','vbat_V'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc47f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds for generator monitoring columns\n",
    "thresholds = {\n",
    "    # Voltages (V)\n",
    "    \"va_V\": (180, 260),\n",
    "    \"vb_V\": (180, 260),\n",
    "    \"vc_V\": (180, 260),\n",
    "    \"mVa_V\": (180, 260),\n",
    "    \"mVb_V\": (180, 260),\n",
    "    \"mVc_v\": (180, 260),\n",
    "    \"va-vb_V\": (310, 450),\n",
    "    \"vb-vc_V\": (310, 450),\n",
    "    \"vc-va_V\": (310, 450),\n",
    "    \"mVa-mBb_V\": (310, 450),\n",
    "    \"mVb-mVc_V\": (310, 450),\n",
    "    \"mVc-mVa_V\": (310, 450),\n",
    "\n",
    "    # Currents (A)\n",
    "    \"ia_A\": (0, 120),\n",
    "    \"ib_A\": (0, 120),\n",
    "    \"ic_A\": (0, 120),\n",
    "\n",
    "    # Active Power (W)\n",
    "    \"pa_W\": (0, 110000),\n",
    "    \"pb_W\": (0, 110000),\n",
    "    \"pc_W\": (0, 110000),\n",
    "    \"ptot_W\": (0, 330000),\n",
    "\n",
    "    # Reactive Power (Var)\n",
    "    \"qa_Var\": (0, 100000),\n",
    "    \"qb_Var\": (0, 100000),\n",
    "    \"qc_Var\": (0, 100000),\n",
    "    \"qtot_Var\": (0, 300000),\n",
    "\n",
    "    # Apparent Power (VA)\n",
    "    \"sa_VA\": (0, 120000),\n",
    "    \"sb_VA\": (0, 120000),\n",
    "    \"sc_VA\": (0, 120000),\n",
    "    \"stot_VA\": (0, 360000),\n",
    "\n",
    "    # Power Factor\n",
    "    \"pfa_None\": (0.7, 1.0),\n",
    "    \"pfb_None\": (0.7, 1.0),\n",
    "    \"pfc_None\": (0.7, 1.0),\n",
    "    \"pftot_None\": (0.7, 1.0),\n",
    "\n",
    "    # Energy\n",
    "    \"expwh_Kwh*10\": (0, float(\"inf\")),\n",
    "    \"expvar_Kvarh*10\": (0, float(\"inf\")),\n",
    "\n",
    "    # Frequency\n",
    "    \"freq_Hz*10\": (495, 505),  # 49.5 - 50.5 Hz\n",
    "\n",
    "    # Environmental / Fuel / Battery\n",
    "    \"temp_Degrees Celsius\": (0, 90),\n",
    "    \"pressure_Bar\": (1, 2.5),\n",
    "    \"fuel_%\": (0, 100),\n",
    "    \"vbat_V\": (11, 14),\n",
    "\n",
    "    # Runtime\n",
    "    \"hours_sec\": (0, float(\"inf\"))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa4ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a lot of events that dont make sense so I want to see if i put 0volt as a nan if there are any  other fields that are als doing this\n",
    "# Replace zero readings with NaN\n",
    "voltage_cols = ['va_V', 'vb_V', 'vc_V','va-vb_V', 'vb-vc_V', 'vc-va_V']\n",
    "df[voltage_cols] = df[voltage_cols].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238f81f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d774946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark any event--> if any field is out of the threshold\n",
    "def detect_event(row):\n",
    "    if row.get(\"is_running\", 0) == 1:\n",
    "        for col in numeric_cols:\n",
    "            low, high = thresholds[col]\n",
    "            val = row[col]\n",
    "            if pd.notnull(val) and (val < low or val > high):\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "df['event'] = df.apply(detect_event, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4354a62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     None\n",
      "1                                     None\n",
      "2                                     None\n",
      "3                                     None\n",
      "4                                     None\n",
      "5                                     None\n",
      "6                                     None\n",
      "7                                     None\n",
      "8                                     None\n",
      "9                                     None\n",
      "10                                    None\n",
      "11                                    None\n",
      "12                                    None\n",
      "13                                    None\n",
      "14                                    None\n",
      "15                                    None\n",
      "16                                    None\n",
      "17                                    None\n",
      "18                                    None\n",
      "19                                    None\n",
      "20                                    None\n",
      "21                                    None\n",
      "22                                    None\n",
      "23    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "24    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "25    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "26    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "27    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "28    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "29    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "30    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "31    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "32    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "33    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "34    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "35    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "36    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "37    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "38    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "39    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "40    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "41    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "42    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "43    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "44    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "45    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "46    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "47    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "48    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "49    vc-va_V: 0.0 out of [310.00, 450.00]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# debug the event to try to see if events were acurately created\n",
    "def detect_event_debug(row):\n",
    "    if row.get(\"is_running\", 0) == 1:\n",
    "        for col in numeric_cols:\n",
    "            low, high = thresholds[col]\n",
    "            val = row[col]\n",
    "            if pd.notnull(val) and (val < low or val > high):\n",
    "                return f\"{col}: {val} out of [{low:.2f}, {high:.2f}]\"\n",
    "    return None\n",
    "\n",
    "print(df.head(50).apply(detect_event_debug, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07dcf36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                       time  event\n",
      "0   2258572  2023-02-24 08:56:14+00:00      0\n",
      "1   2271340  2023-02-28 11:05:31+00:00      0\n",
      "2   2271341  2023-02-28 11:05:41+00:00      0\n",
      "3   2271342  2023-02-28 11:05:51+00:00      0\n",
      "4   2271345  2023-02-28 11:06:01+00:00      0\n",
      "5   2271346  2023-02-28 11:06:11+00:00      0\n",
      "6   2271347  2023-02-28 11:06:21+00:00      0\n",
      "7   2271352  2023-02-28 11:06:31+00:00      0\n",
      "8   2271353  2023-02-28 11:06:41+00:00      0\n",
      "9   2271354  2023-02-28 11:06:51+00:00      0\n",
      "10  2271356  2023-02-28 11:07:01+00:00      0\n",
      "11  2271357  2023-02-28 11:07:11+00:00      0\n",
      "12  2271358  2023-02-28 11:07:21+00:00      0\n",
      "13  2271361  2023-02-28 11:07:31+00:00      0\n",
      "14  2271362  2023-02-28 11:07:41+00:00      0\n",
      "15  2271364  2023-02-28 11:07:51+00:00      0\n",
      "16  2271365  2023-02-28 11:08:01+00:00      0\n",
      "17  2271366  2023-02-28 11:08:11+00:00      0\n",
      "18  2271367  2023-02-28 11:08:21+00:00      0\n",
      "19  2271368  2023-02-28 11:08:31+00:00      0\n"
     ]
    }
   ],
   "source": [
    "df[\"event\"] = df.apply(detect_event, axis=1)\n",
    "\n",
    "print(df[[\"id\",\"time\", \"event\"]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e354bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  min                       max  \\\n",
      "event_group                                                       \n",
      "2           2023-02-28 11:11:18+00:00 2023-03-25 05:40:35+00:00   \n",
      "4           2023-03-25 05:44:35+00:00 2023-03-25 05:52:35+00:00   \n",
      "6           2023-03-25 05:58:35+00:00 2023-03-25 06:08:35+00:00   \n",
      "8           2023-03-25 06:12:35+00:00 2023-03-25 06:32:35+00:00   \n",
      "10          2023-03-25 06:38:35+00:00 2023-03-25 07:12:35+00:00   \n",
      "...                               ...                       ...   \n",
      "132         2025-07-08 07:34:29+00:00 2025-07-08 07:38:29+00:00   \n",
      "134         2025-07-10 04:52:29+00:00 2025-07-10 04:54:28+00:00   \n",
      "136         2025-07-17 07:45:56+00:00 2025-07-17 07:49:56+00:00   \n",
      "138         2025-07-24 04:58:35+00:00 2025-07-24 04:58:35+00:00   \n",
      "140         2025-07-31 04:57:08+00:00 2025-07-31 04:57:08+00:00   \n",
      "\n",
      "             duration_seconds  \n",
      "event_group                    \n",
      "2                   2140157.0  \n",
      "4                       480.0  \n",
      "6                       600.0  \n",
      "8                      1200.0  \n",
      "10                     2040.0  \n",
      "...                       ...  \n",
      "132                     240.0  \n",
      "134                     119.0  \n",
      "136                     240.0  \n",
      "138                       0.0  \n",
      "140                       0.0  \n",
      "\n",
      "[70 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# get duration\n",
    "df = df.sort_values(\"time\").reset_index(drop=True) # ensure the data is sorted by date\n",
    "df['event_group'] = (df['event'] != df['event'].shift()).cumsum()\n",
    "events = df[df['event'] == 1] #only use event rows\n",
    "durations = events.groupby('event_group')['time'].agg(['min', 'max']) #group by event block\n",
    "durations['min'] = pd.to_datetime(durations['min'])\n",
    "durations['max'] = pd.to_datetime(durations['max'])\n",
    "durations['duration_seconds'] = (durations['max'] - durations['min']).dt.total_seconds()\n",
    "\n",
    "print(durations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dff7db0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# preprocessing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 3\u001b[0m X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX\u001b[49m)\n\u001b[0;32m      5\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      6\u001b[0m     X, np\u001b[38;5;241m.\u001b[39mcolumn_stack([T, E]), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, np.column_stack([T, E]), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define deepsurv network\n",
    "class DeepSurvNet(nn.Module):\n",
    "    def __init__(self, in_features, hidden_nodes=[128, 64], dropout=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_nodes = in_features\n",
    "        for nodes in hidden_nodes:\n",
    "            layers.append(nn.Linear(prev_nodes, nodes))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_nodes = nodes\n",
    "        layers.append(nn.Linear(prev_nodes, 1))  # final risk score\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "in_features = X_train.shape[1]\n",
    "net = DeepSurvNet(in_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c981e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap in torchtuples model\n",
    "model = tt.practical.DeepSurv(net, tt.optim.Adam)\n",
    "model.optimizer.set_lr(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb39659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_data = (X_train, y_train)\n",
    "val_data = (X_val, y_val)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 50\n",
    "\n",
    "log = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size, epochs,\n",
    "    val_data=val_data,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d470e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate  concordance index\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Predict risk scores\n",
    "risk_scores = model.predict(X_val).reshape(-1)\n",
    "\n",
    "c_index = concordance_index(y_val[:,0], -risk_scores, y_val[:,1])\n",
    "print(\"Validation Concordance Index (C-index):\", c_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd22ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests to compare accuracy to other models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
